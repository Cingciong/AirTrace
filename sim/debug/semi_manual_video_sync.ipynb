{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing necessary libraries",
   "id": "57b7e582aa75e38b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-18T19:02:00.620106600Z",
     "start_time": "2026-01-18T19:02:00.393159600Z"
    }
   },
   "source": [
    "from pyulog import ULog\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from utilities.PX4CSVPlotter import PX4CSVPlotter\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Environment setup and data paths",
   "id": "baa49ca82fad850e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:02:00.737919500Z",
     "start_time": "2026-01-18T19:02:00.621107100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DATA_DIR = \"../data/1/\"\n",
    "video_path = os.path.join(DATA_DIR, \"mp4.mp4\")\n",
    "output_path = os.path.join(DATA_DIR, \"output.mp4\")\n",
    "ulog_path = os.path.join(DATA_DIR, \"ulg.ulg\")\n",
    "csv_path = os.path.join(DATA_DIR, \"csv\")\n",
    "SAVE_EVERY_N = 1\n",
    "PLOT_EVERY_N = 10\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "cap.release()\n"
   ],
   "id": "3634a2e03eb378f2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Unpacking ULog data and saving to CSV files",
   "id": "839cc1269ea07664"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:02:02.235488400Z",
     "start_time": "2026-01-18T19:02:00.738920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ulog = ULog(ulog_path)\n",
    "for d in ulog.data_list:\n",
    "    df = pd.DataFrame(d.data)\n",
    "    print(d.name)\n",
    "\n",
    "\n",
    "MONITOR_CSV = [\n",
    "    \"vehicle_attitude\",\n",
    "    \"sensor_accel_0.csv\",\n",
    "    \"sensor_gyro_0.csv\",\n",
    "    \"sensor_mag_0.csv\",\n",
    "    \"sensor_baro_0.csv\",\n",
    "    \"sensor_gps_0.csv\",\n",
    "    \"vehicle_local_position_0.csv\",\n",
    "    \"vehicle_global_position_0.csv\"\n",
    "]\n",
    "\n",
    "\n",
    "for data in ulog.data_list:\n",
    "    if data.name in MONITOR_CSV:\n",
    "        df = pd.DataFrame(data.data)\n",
    "\n",
    "        # Convert PX4 timestamp to seconds\n",
    "        if \"timestamp\" in df.columns:\n",
    "            df[\"timestamp_s\"] = df[\"timestamp\"] * 1e-6\n",
    "\n",
    "        filename = f\"{data.name}_{data.multi_id}.csv\"\n",
    "        filepath = os.path.join(DATA_DIR, \"csv\", filename)\n",
    "        df.to_csv(filepath, index=False)\n",
    "        print(f\"Saved {filename}\")\n"
   ],
   "id": "43b64f9d5cc39ea4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actuator_armed\n",
      "actuator_motors\n",
      "actuator_outputs\n",
      "battery_status\n",
      "config_overrides\n",
      "control_allocator_status\n",
      "cpuload\n",
      "distance_sensor_mode_change_request\n",
      "ekf2_timestamps\n",
      "esc_status\n",
      "estimator_aid_src_baro_hgt\n",
      "estimator_aid_src_fake_hgt\n",
      "estimator_aid_src_fake_pos\n",
      "estimator_aid_src_gnss_hgt\n",
      "estimator_aid_src_gnss_pos\n",
      "estimator_aid_src_gnss_vel\n",
      "estimator_aid_src_gravity\n",
      "estimator_aid_src_mag\n",
      "estimator_baro_bias\n",
      "estimator_event_flags\n",
      "estimator_gps_status\n",
      "estimator_innovation_test_ratios\n",
      "estimator_innovation_variances\n",
      "estimator_innovations\n",
      "estimator_sensor_bias\n",
      "estimator_states\n",
      "estimator_status\n",
      "estimator_status_flags\n",
      "event\n",
      "failsafe_flags\n",
      "failure_detector_status\n",
      "gripper\n",
      "home_position\n",
      "hover_thrust_estimate\n",
      "landing_gear\n",
      "manual_control_setpoint\n",
      "mission_result\n",
      "navigator_mission_item\n",
      "navigator_status\n",
      "parameter_update\n",
      "position_setpoint_triplet\n",
      "rate_ctrl_status\n",
      "rtl_status\n",
      "rtl_time_estimate\n",
      "sensor_accel\n",
      "sensor_baro\n",
      "sensor_combined\n",
      "sensor_gps\n",
      "sensor_gyro\n",
      "sensor_gyro_fft\n",
      "sensor_mag\n",
      "sensor_selection\n",
      "sensors_status_imu\n",
      "system_power\n",
      "takeoff_status\n",
      "telemetry_status\n",
      "telemetry_status\n",
      "telemetry_status\n",
      "telemetry_status\n",
      "trajectory_setpoint\n",
      "transponder_report\n",
      "vehicle_acceleration\n",
      "vehicle_air_data\n",
      "vehicle_angular_velocity\n",
      "vehicle_angular_velocity_groundtruth\n",
      "vehicle_attitude\n",
      "vehicle_attitude_groundtruth\n",
      "vehicle_attitude_setpoint\n",
      "vehicle_command\n",
      "vehicle_command_ack\n",
      "vehicle_constraints\n",
      "vehicle_control_mode\n",
      "vehicle_global_position\n",
      "vehicle_global_position_groundtruth\n",
      "vehicle_gps_position\n",
      "vehicle_imu\n",
      "vehicle_imu_status\n",
      "vehicle_land_detected\n",
      "vehicle_local_position\n",
      "vehicle_local_position_groundtruth\n",
      "vehicle_local_position_setpoint\n",
      "vehicle_magnetometer\n",
      "vehicle_rates_setpoint\n",
      "vehicle_status\n",
      "vehicle_thrust_setpoint\n",
      "vehicle_torque_setpoint\n",
      "yaw_estimator_status\n",
      "Saved vehicle_attitude_0.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Importing and processing telemetry data to np.arrays",
   "id": "3692fe0bf5921fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:02:02.580756200Z",
     "start_time": "2026-01-18T19:02:02.320219500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plotter = PX4CSVPlotter(csv_path)\n",
    "\n",
    "all_data = plotter.plot_all(plot=False)\n",
    "angles = all_data[\"att\"]\n",
    "gps = all_data[\"gps\"]\n",
    "\n",
    "gps_time, gps_lon, gps_lat, gps_alt = gps\n",
    "gps_alt = np.array(gps_alt)\n",
    "\n",
    "yaw_att  = np.array(angles[0])\n",
    "pitch_att = np.array(angles[1])\n",
    "roll_att   = np.array(angles[2])\n",
    "time_att  = np.array(angles[3])\n",
    "\n",
    "roll_norm  = (roll_att + 180) % 360 - 180\n",
    "pitch_norm = (pitch_att + 180) % 360 - 180\n",
    "yaw_norm   = (yaw_att + 180) % 360 - 180"
   ],
   "id": "e113f09e1be1bc93",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Normalisation of telemetry data length to gps_time length",
   "id": "e52168361f5ba08b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:02:02.603510900Z",
     "start_time": "2026-01-18T19:02:02.581756800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "M = len(yaw_norm)\n",
    "N = M\n",
    "\n",
    "idx = np.linspace(0, M-1, N).astype(int)\n",
    "\n",
    "gps_time = np.arange(N)\n",
    "yaw_norm   = yaw_norm[idx]\n",
    "pitch_norm = pitch_norm[idx]\n",
    "roll_norm  = roll_norm[idx]\n",
    "\n",
    "old_len = len(gps_alt)\n",
    "\n",
    "x_old = np.linspace(0, 1, old_len)\n",
    "x_new = np.linspace(0, 1, N)\n",
    "\n",
    "gps_alt = np.interp(x_new, x_old, gps_alt)\n",
    "\n",
    "\n",
    "print(gps_time.shape)\n",
    "print(yaw_norm.shape)\n",
    "print(pitch_norm.shape)\n",
    "print(roll_norm.shape)"
   ],
   "id": "ab93fb3c8381262",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64409,)\n",
      "(64409,)\n",
      "(64409,)\n",
      "(64409,)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Saving video frames to np.array",
   "id": "63338f416fefc1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:04:56.967587900Z",
     "start_time": "2026-01-18T19:02:02.604511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(video_path)\n",
    "frames = []\n",
    "frame_idx = 0\n",
    "\n",
    "# Get total frames for tqdm progress\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "with tqdm(total=total_frames, desc=\"Reading frames\") as pbar:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_idx % SAVE_EVERY_N == 0:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame_rgb)\n",
    "\n",
    "        frame_idx += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "frames = np.array(frames)\n",
    "print(\"Frames shape:\", frames.shape)\n"
   ],
   "id": "5ccca2456f5df4bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading frames: 100%|██████████| 5969/5969 [00:50<00:00, 118.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames shape: (5969, 960, 1280, 3)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Helper function to detect start and end of motion in video",
   "id": "1f30f7cde6b32a89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:05:54.588029900Z",
     "start_time": "2026-01-18T19:05:15.769035500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "# --- Parameters ---\n",
    "THRESH_VIDEO = 1        # motion threshold (tune if needed)\n",
    "MIN_STATIC_FRAMES = 2  # how many frames must stay static to confirm end\n",
    "\n",
    "prev_frame = None\n",
    "motion = []\n",
    "\n",
    "frame_idx = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if prev_frame is None:\n",
    "        prev_frame = gray\n",
    "        frame_idx += 1\n",
    "        continue\n",
    "\n",
    "    # compute difference\n",
    "    diff = cv2.absdiff(gray, prev_frame)\n",
    "    mean_diff = diff.mean()\n",
    "    motion.append(mean_diff)\n",
    "\n",
    "    prev_frame = gray\n",
    "    frame_idx += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "motion = np.array(motion)\n",
    "\n",
    "# --- Detect start ---\n",
    "start_frame = np.argmax(motion > THRESH_VIDEO)\n",
    "\n",
    "# --- Detect end ---\n",
    "# Find last index where motion exceeds threshold\n",
    "last_motion = np.where(motion > THRESH_VIDEO)[0]\n",
    "end_frame = last_motion[-1] + MIN_STATIC_FRAMES if len(last_motion) else 0\n",
    "\n",
    "\n",
    "start_frame -=1\n",
    "\n",
    "end_time = end_frame / FPS\n",
    "\n",
    "start_time = start_frame / FPS\n",
    "\n",
    "print(\"Start frame index:\", start_frame)\n",
    "print(\"End frame index:\", end_frame)\n",
    "print(\"Start time (s):\", start_time)\n",
    "print(\"End time (s):\", end_time)\n",
    "print(\"Duration (s):\", end_time - start_time)"
   ],
   "id": "5e1d9abca2c00574",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start frame index: -1\n",
      "End frame index: 5527\n",
      "Start time (s): -0.07722700619869326\n",
      "End time (s): 426.8336632601776\n",
      "Duration (s): 426.9108902663763\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### cutting video frames and telemetry data to match motion period, and normalizing lengths to be the same, preparing for overlay",
   "id": "7178df4d0ec436f5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:06:19.614206700Z",
     "start_time": "2026-01-18T19:06:19.445441400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VIDEO_START_MESS = 22.31860479142235       # video start time in seconds\n",
    "VIDEO_END_MESS = 457.5700117272575        # video end time in seconds\n",
    "TELEMETRY_START_IDX = 16970\n",
    "TELEMETRY_END_IDX = 63418\n",
    "\n",
    "frames_cut = frames[int(VIDEO_START_MESS*FPS):int(VIDEO_END_MESS*FPS)]\n",
    "\n",
    "gps_time_cut = gps_time[TELEMETRY_START_IDX:TELEMETRY_END_IDX]\n",
    "yaw_cut      = yaw_norm[TELEMETRY_START_IDX:TELEMETRY_END_IDX]\n",
    "pitch_cut    = pitch_norm[TELEMETRY_START_IDX:TELEMETRY_END_IDX]\n",
    "roll_cut     = roll_norm[TELEMETRY_START_IDX:TELEMETRY_END_IDX]\n",
    "gps_alt_cut  = gps_alt[TELEMETRY_START_IDX:TELEMETRY_END_IDX]\n",
    "\n",
    "M = len(frames_cut)\n",
    "N = M\n",
    "idx = np.linspace(0, len(yaw_cut) - 1, N).astype(int)\n",
    "\n",
    "gps_time_cut = np.arange(N)\n",
    "yaw_cut      = yaw_cut[idx]\n",
    "pitch_cut    = pitch_cut[idx]\n",
    "roll_cut     = roll_cut[idx]\n",
    "\n",
    "old_len = len(gps_alt_cut)\n",
    "x_old = np.linspace(0, 1, old_len)\n",
    "x_new = np.linspace(0, 1, N)\n",
    "\n",
    "gps_alt_cut = np.interp(x_new, x_old, gps_alt_cut)\n",
    "\n",
    "print(\"gps_time_cut:\", gps_time_cut.shape)\n",
    "print(\"yaw_cut:\", yaw_cut.shape)\n",
    "print(\"pitch_cut:\", pitch_cut.shape)\n",
    "print(\"roll_cut:\", roll_cut.shape)\n",
    "print(\"gps_alt_cut:\", gps_alt_cut.shape)\n",
    "print(\"frames_cut:\", frames_cut.shape)"
   ],
   "id": "fb6551b86b02117c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gps_time_cut: (5636,)\n",
      "yaw_cut: (5636,)\n",
      "pitch_cut: (5636,)\n",
      "roll_cut: (5636,)\n",
      "gps_alt_cut: (5636,)\n",
      "frames_cut: (5636, 960, 1280, 3)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Debug visualization of telemetry data overlaid on video frames",
   "id": "45997b71e9b57eef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-18T19:09:16.468791800Z",
     "start_time": "2026-01-18T19:06:21.552442600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N = min(len(frames_cut), len(gps_time_cut), len(gps_alt_cut), len(pitch_cut), len(roll_cut))\n",
    "\n",
    "T = 1 / 30\n",
    "\n",
    "for i in range(N):\n",
    "    frame = frames_cut[i].copy()\n",
    "    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    text = (\n",
    "        f\"Idx: {i} | \"\n",
    "        f\"Time: {gps_time_cut[i]:.2f}s | \"\n",
    "        f\"Alt: {gps_alt_cut[i]:.2f}m | \"\n",
    "        f\"Pitch: {pitch_cut[i]:.2f} | \"\n",
    "        f\"Roll: {roll_cut[i]:.2f}\"\n",
    "    )\n",
    "\n",
    "    cv2.putText(\n",
    "        frame_bgr,\n",
    "        text,\n",
    "        (20, 40),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.7,\n",
    "        (0, 255, 0),\n",
    "        2\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"Telemetry Video\", frame_bgr)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    cv2.waitKey(int(T * 1000))\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ],
   "id": "4b4e9b8eaa64a191",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "e9e5529853d2947a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
