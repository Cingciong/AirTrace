# AirTrace - Multi-Phase Video & Motion Analysis System

Complete pipeline for capturing, analyzing, and synchronizing video with drone telemetry data.

---

## ğŸ“‹ Project Overview

**AirTrace** is a two-phase system:

1. **[Phase 1: Ground Testing](#-phase-1-ground-testing)** - Capture video in terrain and analyze motion using optical flow
2. **[Phase 2: Simulation](#-phase-2-simulation-drone-data)** - Synchronize video with PX4 drone telemetry data

---

# ğŸ”¸ Phase 1: Ground Testing

**Location:** `ground_testing/`

### What It Does
Records videos from ground-level tests and uses **sparse optical flow** to track motion and displacement in the terrain.

### Purpose
- Validate motion detection algorithms before drone deployment
- Measure terrain traversal using video analysis
- Test height measurement from video
- Extract motion vectors (Î”x, Î”y, trajectory)

### Files

| File | Purpose |
|------|---------|
| `main.py` | Core optical flow analysis pipeline |
| `csv.ipynb` | Sensor data processing (acceleration, orientation, GPS) |
| `csv_intepreter.py` | Parse and visualize sensor data from CSV files |
| `height measuring.ipynb` | Altitude estimation from video |
| `main.ipynb` | Interactive workflow notebook |

### How It Works: `main.py`

**Core Pipeline:**

```
Video File (.mov)
    â†“
[Preprocess]
â”œâ”€ Load .mov file
â”œâ”€ Resize frames (target height: 360px)
â”œâ”€ Crop unwanted pixels (200px left)
â””â”€ Select frame range
    â†“
[Sparse Optical Flow]
â”œâ”€ Detect good features (500+ corners/edges)
â”œâ”€ Track features frame-to-frame
â”œâ”€ Calculate motion vectors (Î”x, Î”y)
â””â”€ Filter by tracking quality
    â†“
[Analysis & Visualization]
â”œâ”€ Plot Î”x per frame
â”œâ”€ Plot Î”y per frame
â”œâ”€ Compute 2D trajectory
â””â”€ Calculate cumulative displacement
    â†“
Output: Motion plots + trajectory path
```

#### Key Parameters

```python
video_path = "G:/projekt gropwy/22.10.2025/video/raw/720p/5.1.mov"
target_height = 360              # Resize to height
frame_interval = 2               # Process every Nth frame
cut_pixels = 200                 # Crop left edge (px)
start_frame = 210                # Skip first N frames
meters_per_pixel_y = 0.0006      # Scale calibration (m/px)
fps_capture = 1209               # Original capture FPS
```

#### Output Visuals

1. **Î”x Plot** - Horizontal motion magnitude per frame (pixels)
2. **Î”y Plot** - Vertical motion magnitude per frame (pixels)  
3. **2D Trajectory** - XY path showing cumulative displacement

### Sensor Data Processing: `csv.ipynb`

Processes sensor CSV files with multi-step pipeline:

**Input:** CSV files with accelerometer, orientation, GPS data

**Steps:**
1. **Load Data** - Parse CSV with locale-specific separators (`,` or `;`)
2. **Coordinate Transform** - Convert acceleration from local â†’ global (NED frame)
3. **Filtering** - Apply low-pass Butterworth filter (cutoff: 1 Hz, order: 3)
4. **Integration** - Double integrate: acceleration â†’ velocity â†’ position
5. **Visualization** - Plot in 2D/3D

**Output:** 
- Filtered accelerations in global frame
- Velocity vectors
- Position trajectory
- 3D visualization with acceleration overlay

### Example Ground Test

```python
# ground_testing/main.py

video_path = "5.1.mov"  # Test video
# Reads 5.1.mov
# Detects features in 500+ points
# Computes sparse optical flow
# Outputs:
#   â”œâ”€ Î”x plot
#   â”œâ”€ Î”y plot
#   â””â”€ Trajectory plot
```

### Data Types

| Data | Type | Range | Meaning |
|------|------|-------|---------|
| **Î”x** | float | -50 to +50 px | Horizontal motion per frame |
| **Î”y** | float | -50 to +50 px | Vertical motion per frame |
| **Trajectory** | ndarray (N,2) | varies | Cumulative XY displacement |

---

# ğŸ”¶ Phase 2: Simulation (Drone Data)

**Location:** `sim/`

### What It Does
Synchronizes drone video with PX4 autopilot telemetry to create frame-by-frame paired data with attitude and altitude.

### Purpose
- Combine video with drone orientation data
- Create training datasets for ML models
- Analyze drone behavior during flight
- Pair video frames with UAV state (yaw, pitch, roll, altitude)

### Files

| File | Purpose |
|------|---------|
| `main.ipynb` | Main workflow & analysis |
| `utilities/TelementryVideoSync.py` | Core synchronization class |
| `utilities/PX4CSVPlotter.py` | Parse PX4 sensor data |
| `data/1/mp4.mp4` | Drone video recording |
| `data/1/ulg.ulg` | PX4 telemetry log |
| `data/1/csv/` | Converted sensor CSVs |

### How It Works: `TelemetryVideoSync` Class

**Complete Pipeline:**

```
ULog File (ulg.ulg)
    â†“
[read_telemetry()]
â”œâ”€ Parse ULog with pyulog
â”œâ”€ Extract sensor data
â”‚   â”œâ”€ vehicle_attitude (yaw, pitch, roll)
â”‚   â”œâ”€ sensor_gps_0 (lat, lon, alt)
â”‚   â”œâ”€ sensor_accel_0 (accelerometer)
â”‚   â”œâ”€ sensor_gyro_0 (gyroscope)
â”‚   â””â”€ ... other sensors
â””â”€ Convert to CSV files
    â†“
[load_telemetry()]
â”œâ”€ Read CSV files (PX4CSVPlotter)
â”œâ”€ Extract attitude angles
â”œâ”€ Normalize to [-180, +180]Â°
â”œâ”€ Resample to N samples
â””â”€ Store in memory
    â†“
Video File (mp4.mp4)
    â†“
[save_video_to_arrays()]
â”œâ”€ Open MP4 with OpenCV
â”œâ”€ Load all frames
â”œâ”€ Convert BGR â†’ RGB
â””â”€ Store as NumPy array
    â†“
[analyze_telemetry()]
â”œâ”€ Cut video (time mask):
â”‚   start = VIDEO_START_TIME * FPS
â”‚   end = VIDEO_END_TIME * FPS
â”œâ”€ Cut telemetry (index mask):
â”‚   [TELEMETRY_START_IDX : TELEMETRY_END_IDX]
â”œâ”€ Interpolate to match lengths
â”‚   frames.shape[0] == telemetry.shape[0]
â””â”€ Align frame-by-frame
    â†“
[play_telemetry_video()]
â”œâ”€ Display frames
â”œâ”€ Overlay telemetry text:
â”‚   - Frame index
â”‚   - Altitude (m)
â”‚   - Angles (Â°)
â”‚   - Timestamp
â””â”€ Save visualization
```

#### Methods

| Method | Input | Output | Purpose |
|--------|-------|--------|---------|
| `read_telemetry()` | .ulg file | .csv files | Convert ULog to CSV |
| `load_telemetry()` | .csv files | NumPy arrays | Parse & normalize |
| `save_video_to_arrays()` | .mp4 file | NumPy array | Load video frames |
| `analyze_telemetry()` | frames + telemetry | Synchronized pairs | Cut & align |
| `play_telemetry_video()` | synchronized data | Display window | Visualize overlay |
| `debug_detect_motion_video()` | frames | Motion plot | Find motion start/end |

#### Key Parameters

```python
# Telemetry cutting indices
TELEMETRY_START_IDX = 16970        # Start index in telemetry array
TELEMETRY_END_IDX = 63418          # End index in telemetry array

# Video cutting time (seconds)
VIDEO_START_MESS = 22.31860479     # Start time in seconds
VIDEO_END_MESS = 457.5700117       # End time in seconds

# Other options
SAVE_EVERY_N = 1                   # Sample every Nth frame
PLOT_EVERY_N = 10                  # Plot telemetry every Nth frame
```

#### Usage Example

```python
from utilities.TelementryVideoSync import TelemetryVideoSync

sync = TelemetryVideoSync(
    telemetry_start_idx=16970,
    telemetry_end_idx=63418,
    video_start_time=22.31860479,
    video_end_time=457.5700117,
    video_path="data/1/mp4.mp4",
    ulog_path="data/1/ulg.ulg",
    csv_path="data/1/csv",
)

# Step 1: Convert ULog â†’ CSV
sync.read_telemetry()

# Step 2: Load & process all data
sync.analyze_telemetry()

# Step 3: Display synchronized video
sync.play_telemetry_video()
```

### Output Data Structure

Each synchronized frame contains:

```python
{
    'frame': ndarray (H, W, 3)     # Video frame (RGB)
    'frame_idx': int               # Frame number
    'yaw': float                   # Rotation [-180, +180]Â°
    'pitch': float                 # Nose angle [-180, +180]Â°
    'roll': float                  # Wing angle [-180, +180]Â°
    'gps_alt': float              # Altitude (meters)
    'gps_time': float             # Timestamp
}
```

### Angle Definitions

| Angle | Axis | Meaning |
|-------|------|---------|
| **Yaw** | Z (vertical) | Compass heading, 0Â°=North |
| **Pitch** | Y (lateral) | Nose up (+) / down (-) |
| **Roll** | X (longitudinal) | Right wing up (+) / down (-) |

---

## ğŸ—‚ï¸ Complete Project Structure

```
CamTrack/
â”‚
â”œâ”€â”€ ğŸ”¸ PHASE 1: Ground Testing
â”‚   â”œâ”€â”€ ground_testing/
â”‚   â”‚   â”œâ”€â”€ main.py                    â­ Optical flow analysis
â”‚   â”‚   â”œâ”€â”€ csv.ipynb                  ğŸ““ Sensor data processing
â”‚   â”‚   â”œâ”€â”€ csv_intepreter.py          ğŸ”§ CSV parser & viz
â”‚   â”‚   â”œâ”€â”€ height measuring.ipynb     ğŸ“ Altitude estimation
â”‚   â”‚   â”œâ”€â”€ main.ipynb                 ğŸ““ Interactive workflow
â”‚   â”‚   â”œâ”€â”€ videos/                    ğŸ¥ Test video files
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ __pycache__/
â”‚   â”‚
â”œâ”€â”€ ğŸ”¶ PHASE 2: Simulation/Drone
â”‚   â”œâ”€â”€ sim/
â”‚   â”‚   â”œâ”€â”€ main.ipynb                          ğŸ““ Main workflow
â”‚   â”‚   â”œâ”€â”€ semi_manual_video_sync.ipynb        ğŸ““ Manual sync
â”‚   â”‚   â”œâ”€â”€ semi_manual_video_sync.py           ğŸ“ Original sync
â”‚   â”‚   â”œâ”€â”€ utilities/
â”‚   â”‚   â”‚   â”œâ”€â”€ TelementryVideoSync.py         â­ Core sync class
â”‚   â”‚   â”‚   â”œâ”€â”€ PX4CSVPlotter.py               ğŸ”§ CSV parser
â”‚   â”‚   â”‚   â”œâ”€â”€ plt.py                        ğŸ› ï¸ Plotting utils
â”‚   â”‚   â”‚   â””â”€â”€ __pycache__/
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ data/
â”‚   â”‚       â””â”€â”€ 1/
â”‚   â”‚           â”œâ”€â”€ mp4.mp4                    ğŸ¥ Drone video
â”‚   â”‚           â”œâ”€â”€ ulg.ulg                    ğŸ“Š Telemetry log
â”‚   â”‚           â””â”€â”€ csv/                       ğŸ“ Extracted CSVs
â”‚   â”‚               â”œâ”€â”€ vehicle_attitude_0.csv
â”‚   â”‚               â”œâ”€â”€ sensor_gps_0.csv
â”‚   â”‚               â”œâ”€â”€ sensor_accel_0.csv
â”‚   â”‚               â””â”€â”€ ... (other sensors)
â”‚   â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md                                  (this file)
â””â”€â”€ README_NEW.md                             (detailed version)
```

---

## ğŸ”„ Complete Workflow Path

```
PROJECT START
  â”‚
  â”œâ”€â–º ğŸ”¸ PHASE 1: Ground Testing
  â”‚   â”‚
  â”‚   â”œâ”€ Record video in terrain
  â”‚   â”‚   â””â”€ Video files â†’ ground_testing/videos/
  â”‚   â”‚
  â”‚   â”œâ”€ Analyze motion (main.py)
  â”‚   â”‚   â”œâ”€ Input: .mov video
  â”‚   â”‚   â”œâ”€ Process: Sparse optical flow
  â”‚   â”‚   â””â”€ Output: Î”x, Î”y plots + trajectory
  â”‚   â”‚
  â”‚   â”œâ”€ Validate algorithms
  â”‚   â”‚   â””â”€ Review motion detection quality
  â”‚   â”‚
  â”‚   â””â”€ Approve for drone phase
  â”‚       â”‚
  â”‚       â†“
  â”‚
  â”œâ”€â–º ğŸ”¶ PHASE 2: Simulation/Drone
  â”‚   â”‚
  â”‚   â”œâ”€ Record drone flight + telemetry
  â”‚   â”‚   â”œâ”€ Video â†’ data/1/mp4.mp4
  â”‚   â”‚   â””â”€ ULog â†’ data/1/ulg.ulg
  â”‚   â”‚
  â”‚   â”œâ”€ Read telemetry (TelemetryVideoSync)
  â”‚   â”‚   â”œâ”€ Convert: ULog â†’ CSV
  â”‚   â”‚   â””â”€ Store: data/1/csv/
  â”‚   â”‚
  â”‚   â”œâ”€ Process data
  â”‚   â”‚   â”œâ”€ Load telemetry (attitudes, altitude)
  â”‚   â”‚   â”œâ”€ Load video frames
  â”‚   â”‚   â””â”€ Normalize angles & lengths
  â”‚   â”‚
  â”‚   â”œâ”€ Synchronize
  â”‚   â”‚   â”œâ”€ Cut video (time mask)
  â”‚   â”‚   â”œâ”€ Cut telemetry (index mask)
  â”‚   â”‚   â””â”€ Interpolate â†’ same length
  â”‚   â”‚
  â”‚   â”œâ”€ Visualize
  â”‚   â”‚   â”œâ”€ Display video with overlay
  â”‚   â”‚   â”œâ”€ Show: altitude, angles, timestamp
  â”‚   â”‚   â””â”€ Save output video
  â”‚   â”‚
  â”‚   â””â”€ Generate dataset
  â”‚       â””â”€ Paired frame + telemetry data
  â”‚
  â””â”€â–º PROJECT END
      (Ready for ML training / analysis)
```

---

## ğŸ“Š Phase Comparison

| Feature | Phase 1 (Ground) | Phase 2 (Drone) |
|---------|-----------------|-----------------|
| **Location** | `ground_testing/` | `sim/` |
| **Input** | .mov video | .mp4 video + .ulg log |
| **Analysis Type** | Optical flow | Sensor fusion |
| **Key Method** | Sparse optical flow | Telemetry sync |
| **Output** | Motion vectors | Paired frames + telemetry |
| **Purpose** | Algorithm validation | Dataset creation |
| **Sensors Used** | Video only | IMU, GPS, barometer, video |
| **Output Data** | Î”x, Î”y, trajectory | Frame + yaw/pitch/roll/alt |

---

## ğŸš€ Getting Started

### Phase 1: Ground Testing

```bash
cd ground_testing
python main.py
# Output: Motion plots and trajectory
```

### Phase 2: Drone Data Sync

```python
from utilities.TelementryVideoSync import TelemetryVideoSync

sync = TelemetryVideoSync()
sync.read_telemetry()      # ULog â†’ CSV
sync.analyze_telemetry()   # Load & process
sync.play_telemetry_video()  # Display
```

---

## ğŸ’¾ Dependencies

```
opencv-python      # Video processing
numpy              # Array operations
pandas             # CSV handling
matplotlib         # Plotting
pyulog             # ULog parsing
scipy              # Signal processing
```

Install:
```bash
pip install opencv-python numpy pandas matplotlib pyulog scipy
```

---

## ğŸ“ Notes

- **Phase 1** validates algorithms on ground
- **Phase 2** applies them to drone data
- Data flows sequentially: Phase 1 â†’ Phase 2
- Both phases produce synchronized motion data
